def fine_tune_model(pretrained_model, twi_data, afroLM_embeddings, epochs=10, learning_rate=1e-4):
    """
    Fine-tunes the selected TTS model using Twi data and AfroLM embeddings.

    Parameters:
    - pretrained_model: The pre-trained TTS model to be fine-tuned.
    - twi_data: The processed Twi text data for training.
    - afroLM_embeddings: The contextualized embeddings generated by AfroLM.
    - epochs: Number of training epochs (default is 10).
    - learning_rate: Learning rate for the optimizer (default is 1e-4).

    Returns:
    - fine_tuned_model: The fine-tuned TTS model.
    """
    # Set up the training loop
    optimizer = torch.optim.Adam(pretrained_model.parameters(), lr=learning_rate)
    criterion = torch.nn.MSELoss()

    for epoch in range(epochs):
        for inputs, targets in twi_data:
            optimizer.zero_grad()
            outputs = pretrained_model(inputs, afroLM_embeddings)
            loss = criterion(outputs, targets)
            loss.backward()
            optimizer.step()
        print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')

    # Save the fine-tuned model
    fine_tuned_model_path = "models/fine_tuned/fine_tuned_twi_tts_model.pt"
    torch.save(pretrained_model.state_dict(), fine_tuned_model_path)

    return fine_tuned_model_path

def load_fine_tuned_model(model_path):
    """
    Loads the fine-tuned TTS model from the specified path.

    Parameters:
    - model_path: Path to the fine-tuned model file.

    Returns:
    - fine_tuned_model: The loaded fine-tuned TTS model.
    """
    # Load the model (pseudo code)
    fine_tuned_model = YourModelClass()
    fine_tuned_model.load_state_dict(torch.load(model_path))
    return fine_tuned_model
